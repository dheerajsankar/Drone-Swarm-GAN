# -*- coding: utf-8 -*-
"""Drone Swarm GAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bONMA_wic3szRdPvSBT5CYDfGxwabyNh
"""

import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import MinMaxScaler
#Simulated Data
drone_data = pd.DataFrame({
    'Drone_ID':np.tile(np.arange(1,6),20),
    'X_Position':np.random.uniform(0,100,100),
    'Y_Position':np.random.uniform(0, 100, 100),
    'Z_Position':np.random.uniform(10,100,100),
    'Speed':np.random.uniform(5,20,100),
    'Collision_Risk':np.random.choice([0,1],size = 100,p=[0.9,0.1])
})
print("Sample Drone Data")
drone_data.head()

#Drop Irrelevant Data like Drone ID, also normalize numeric columns
scaler = MinMaxScaler()
data_numeric = drone_data.drop(columns = ['Drone_ID'])
data_norm = scaler.fit_transform(data_numeric)
#Converted normalized data back to DF
norm_df = pd.DataFrame(data_norm, columns = data_numeric.columns)
print(norm_df.head())

#Build the Generator
latent_dim=100
def build_generator(latent_dim):
    model = Sequential([
        Dense(128, input_dim = latent_dim),
        LeakyReLU(alpha=0.01),
        BatchNormalization(momentum=0.8),
        Dense(256),
        LeakyReLU(alpha=0.01),
        BatchNormalization(momentum=0.8),
        Dense(512),
        LeakyReLU(alpha=0.01),
        BatchNormalization(momentum=0.8),
        Dense(5, activation='sigmoid')
    ])
    return model
generator = build_generator(latent_dim)
generator.summary()

#Build the Discriminator

def build_discriminator():
    model = Sequential([
        Dense(512, input_shape=(5,)),
        LeakyReLU(alpha=0.01),
        Dense(256),
        LeakyReLU(alpha=0.01),
        Dense(128),
        LeakyReLU(alpha=0.01),
        Dense(1, activation = 'sigmoid')
    ])
    model.compile(loss='binary_crossentropy',optimizer = Adam(), metrics=['accuracy'])
    return model
discriminator = build_discriminator()
discriminator.summary()

#Build the GAN

def build_gan(generator, discriminator):
    discriminator.trainable=False
    model = Sequential([generator,discriminator])
    model.compile(loss = 'binary_crossentropy',optimizer = Adam())
    return model
gan = build_gan(generator, discriminator)
gan.summary()

#Train the GAN
def train_gan(gan, generator, discriminator, data, epochs = 10000, batch_size = 128, latent_dim=100):
    for epoch in range(epochs):
        idx = np.random.randint(0,data.shape[0], batch_size)
        real_data = data[idx]
        noise = np.random.normal(0,1,(batch_size,latent_dim))
        fake_data = generator.predict(noise)
        real_labels = np.ones((batch_size,1))
        fake_labels = np.zeros((batch_size,1))
        d_loss_real = discriminator.train_on_batch(real_data, real_labels)
        d_loss_fake = discriminator.train_on_batch(fake_data, fake_labels)
        noise = np.random.normal(0,1,(batch_size,latent_dim))
        valid_labels = np.ones((batch_size,1))
        g_loss = gan.train_on_batch(noise,valid_labels)
        if epoch%1000 == 0:
            print(f"Epoch{epoch}:D Loss:{0.5 * (d_loss_real[0]+d_loss_fake[0])},G Loss:{g_loss}")

#Prepare for training
normalized_array=norm_df.values
train_gan(gan, generator, discriminator, normalized_array, epochs = 5000, batch_size = 32, latent_dim=latent_dim)

#Genrate Synthertic Drone Swarm Data
noise = np.random.normal(0,1,size=(100,latent_dim))
generated_data = generator.predict(noise)
generated_data_rescaled = scaler.inverse_transform(generated_data)

#Convert to DataFrame for analysis
generated_df = pd.DataFrame(generated_data_rescaled, columns=data_numeric.columns)
print("\nSynthetic drone swarm data:")
print(generated_df.head())

